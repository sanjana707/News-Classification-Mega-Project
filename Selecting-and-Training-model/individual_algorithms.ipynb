{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de25b114-0c99-4520-9402-3c7f6004733c",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833fb0dd-0a34-4f5b-87e0-8e5ec3b6afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ef4dea-19bf-4723-b9f9-c72e877aec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data_processed.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text_parsed'],                                                  \n",
    "                                                    data['Category_target'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023c5b79-1492-4951-b101-eb006020de04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48974, 12244)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac314b11-1fb2-4002-8704-c7523b763ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Technology', 'Education', 'Well', 'Theater', 'Your Money', 'Opinion', 'Global Business', 'Television', 'Health', 'Food', 'Travel', 'Real Estate', 'Books', 'Fashion', 'Dance', 'Music', 'Style', 'Art & Design', 'Movies', 'Science', 'Sports', 'Media', 'Economy', 'Automobiles'}\n"
     ]
    }
   ],
   "source": [
    "categories = set(data['section'].values.tolist())\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e97ae36-0918-418b-9b28-07d0a403ba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "no_of_categories = len(categories)\n",
    "print(no_of_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ad3fa-a3d7-41b9-ad96-1649ff1dcc31",
   "metadata": {},
   "source": [
    "# Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8fcb4a-8d6f-44b8-b454-106de7f2888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359a293d-e808-4727-9b40-479f0485ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08095b3d-e626-4424-84e8-a41db612eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "# print(features_train)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "# print(features_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b088b6-9c6f-42dd-a113-88a935b4c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(features_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d370a51a-c83c-4a89-a118-cce7aeb8952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('features_train.npy', features_train)\n",
    "np.save('features_test.npy', features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3c212-45cf-455f-8fc4-b5965cc5c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('labels_train.npy', np.array(labels_train))\n",
    "np.save('labels_test.npy', np.array(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2cfab-5bd9-49a6-9c13-9085754667a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c6a0cd-89a6-4cbe-89b6-3fba8f7179f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = np.load('features_test.npy')\n",
    "features_train = np.load('features_train.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b195d-bca7-46d8-b9f5-6958bd94b3d1",
   "metadata": {},
   "source": [
    "# Train individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef0ba827-86e0-41c8-9dbd-3ad84d8869c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404de2a-2f2b-41c8-9b0e-aa05a5811ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7059245-a50e-434b-897a-6de3406dcc00",
   "metadata": {},
   "source": [
    "#### 1. Naive Bayes: \n",
    "This is a probabilistic algorithm that is easy to implement and works well with text data. It's fast and requires less training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "080b0538-b65c-4da6-a674-1956af4edb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.34580202548186867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.27      0.40       594\n",
      "           1       0.21      0.53      0.30       346\n",
      "           2       0.62      0.15      0.24       636\n",
      "           3       0.34      0.87      0.49       567\n",
      "           4       0.22      0.44      0.30       346\n",
      "           5       0.06      0.37      0.10       155\n",
      "           6       0.72      0.14      0.24       613\n",
      "           7       0.46      0.45      0.45       601\n",
      "           8       0.14      0.73      0.23       214\n",
      "           9       0.66      0.30      0.42       586\n",
      "          10       0.71      0.23      0.35       609\n",
      "          11       0.43      0.28      0.34       601\n",
      "          12       0.81      0.43      0.56       635\n",
      "          13       0.55      0.14      0.22       603\n",
      "          14       0.67      0.35      0.46       621\n",
      "          15       0.55      0.29      0.38       585\n",
      "          16       0.74      0.55      0.63       625\n",
      "          17       0.18      0.04      0.06       554\n",
      "          18       0.61      0.32      0.42       577\n",
      "          19       0.68      0.65      0.66       601\n",
      "          20       0.38      0.32      0.35       612\n",
      "          21       0.66      0.17      0.28       578\n",
      "          22       0.05      0.55      0.09       146\n",
      "          23       0.10      0.19      0.13       239\n",
      "\n",
      "    accuracy                           0.35     12244\n",
      "   macro avg       0.47      0.36      0.34     12244\n",
      "weighted avg       0.54      0.35      0.37     12244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(features_train, labels_train)\n",
    "model_predictions = nb_model.predict(features_test)\n",
    "print('Accuracy: ', accuracy_score(labels_test, model_predictions))\n",
    "print(classification_report(labels_test, model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5af3a266-b203-4b03-90f1-47f315a3afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = './models/gaussian_nb_model.sav'\n",
    "pickle.dump(nb_model, open(filename, 'wb'))\n",
    "\n",
    "# # later, load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6037b-7756-49ee-822c-049e95fd666e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a354ebc8-127c-4794-90f3-edf30ab81aeb",
   "metadata": {},
   "source": [
    "#### 2. Logistic Regression: \n",
    "This algorithm works well for binary and multi-class classification problems. It's a linear model that learns the relationships between the input features and the output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10e78ed0-9844-4628-91b3-b342b99868fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Accuracy:  0.7252531852335838 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       594\n",
      "           1       0.80      0.78      0.79       346\n",
      "           2       0.67      0.75      0.71       636\n",
      "           3       0.91      0.90      0.90       567\n",
      "           4       0.71      0.65      0.68       346\n",
      "           5       0.64      0.56      0.60       155\n",
      "           6       0.65      0.56      0.60       613\n",
      "           7       0.73      0.78      0.75       601\n",
      "           8       0.73      0.67      0.70       214\n",
      "           9       0.72      0.72      0.72       586\n",
      "          10       0.65      0.64      0.65       609\n",
      "          11       0.77      0.81      0.79       601\n",
      "          12       0.82      0.81      0.81       635\n",
      "          13       0.64      0.74      0.69       603\n",
      "          14       0.74      0.81      0.77       621\n",
      "          15       0.71      0.75      0.73       585\n",
      "          16       0.83      0.89      0.86       625\n",
      "          17       0.37      0.32      0.34       554\n",
      "          18       0.72      0.75      0.74       577\n",
      "          19       0.82      0.81      0.81       601\n",
      "          20       0.83      0.82      0.83       612\n",
      "          21       0.68      0.71      0.70       578\n",
      "          22       0.63      0.15      0.24       146\n",
      "          23       0.56      0.44      0.49       239\n",
      "\n",
      "    accuracy                           0.73     12244\n",
      "   macro avg       0.71      0.69      0.69     12244\n",
      "weighted avg       0.72      0.73      0.72     12244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "print(lr_model.get_params())\n",
    "lr_model.fit(features_train, labels_train)\n",
    "\n",
    "lr_model_predictions = lr_model.predict(features_test)\n",
    "print('\\nAccuracy: ', accuracy_score(labels_test, lr_model_predictions), \"\\n\")\n",
    "print(classification_report(labels_test, lr_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7f5c6c2-2b9e-4d34-97b7-0d2e446a6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = './models/lr_model.sav'\n",
    "pickle.dump(lr_model, open(filename, 'wb'))\n",
    "\n",
    "# # later, load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec33f06-0bf1-4fbe-9727-c000a444ac1d",
   "metadata": {},
   "source": [
    "#### 3. Support Vector Machines (SVM): \n",
    "This is a powerful algorithm that can be used for both linear and non-linear classification problems. SVMs work by finding the best hyperplane that separates the data into different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d959c05a-925a-4134-bc2b-0bf8da16640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.7174942829140804 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       594\n",
      "           1       0.78      0.79      0.78       346\n",
      "           2       0.67      0.73      0.70       636\n",
      "           3       0.90      0.89      0.90       567\n",
      "           4       0.68      0.66      0.67       346\n",
      "           5       0.58      0.68      0.63       155\n",
      "           6       0.61      0.54      0.57       613\n",
      "           7       0.71      0.79      0.75       601\n",
      "           8       0.69      0.68      0.69       214\n",
      "           9       0.70      0.72      0.71       586\n",
      "          10       0.64      0.63      0.63       609\n",
      "          11       0.76      0.82      0.79       601\n",
      "          12       0.83      0.82      0.82       635\n",
      "          13       0.65      0.72      0.69       603\n",
      "          14       0.75      0.80      0.77       621\n",
      "          15       0.70      0.72      0.71       585\n",
      "          16       0.87      0.87      0.87       625\n",
      "          17       0.36      0.32      0.34       554\n",
      "          18       0.75      0.73      0.74       577\n",
      "          19       0.83      0.80      0.82       601\n",
      "          20       0.84      0.80      0.82       612\n",
      "          21       0.68      0.67      0.67       578\n",
      "          22       0.50      0.23      0.32       146\n",
      "          23       0.52      0.44      0.47       239\n",
      "\n",
      "    accuracy                           0.72     12244\n",
      "   macro avg       0.70      0.69      0.69     12244\n",
      "weighted avg       0.71      0.72      0.71     12244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# create SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# train the classifier on the training data\n",
    "svm_model.fit(features_train, labels_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "svm_model_predictions = svm_model.predict(features_test)\n",
    "\n",
    "# evaluate the accuracy of the classifier\n",
    "print('\\nAccuracy: ', accuracy_score(labels_test, svm_model_predictions), \"\\n\")\n",
    "print(classification_report(labels_test, svm_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b980bc7-a4b7-4cdc-94fb-940401d6abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = './models/svm_model.sav'\n",
    "pickle.dump(svm_model, open(filename, 'wb'))\n",
    "\n",
    "# # later, load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c7dca-5699-4c1e-b550-32eee8b22299",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#### 4. Random Forest: \n",
    "This is an ensemble learning algorithm that combines multiple decision trees to improve the accuracy of the classification. It works well for both text and non-text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94ba2e41-9e79-4297-b1af-3c603cceb7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.6534629206141783 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72       594\n",
      "           1       0.72      0.73      0.73       346\n",
      "           2       0.58      0.69      0.63       636\n",
      "           3       0.88      0.87      0.88       567\n",
      "           4       0.66      0.57      0.61       346\n",
      "           5       0.50      0.62      0.55       155\n",
      "           6       0.59      0.52      0.56       613\n",
      "           7       0.59      0.77      0.67       601\n",
      "           8       0.55      0.48      0.51       214\n",
      "           9       0.66      0.67      0.66       586\n",
      "          10       0.60      0.50      0.54       609\n",
      "          11       0.70      0.84      0.77       601\n",
      "          12       0.79      0.76      0.77       635\n",
      "          13       0.50      0.60      0.55       603\n",
      "          14       0.62      0.74      0.67       621\n",
      "          15       0.63      0.62      0.63       585\n",
      "          16       0.72      0.84      0.77       625\n",
      "          17       0.25      0.10      0.14       554\n",
      "          18       0.66      0.70      0.68       577\n",
      "          19       0.73      0.75      0.74       601\n",
      "          20       0.77      0.81      0.79       612\n",
      "          21       0.62      0.55      0.58       578\n",
      "          22       0.69      0.12      0.21       146\n",
      "          23       0.53      0.23      0.32       239\n",
      "\n",
      "    accuracy                           0.65     12244\n",
      "   macro avg       0.64      0.62      0.61     12244\n",
      "weighted avg       0.64      0.65      0.64     12244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model  = RandomForestClassifier(random_state=1)\n",
    "rf_model.fit(features_train, labels_train)\n",
    "rf_model_predictions = rf_model.predict(features_test)\n",
    "\n",
    "# evaluate the accuracy of the classifier\n",
    "print('\\nAccuracy: ', accuracy_score(labels_test, rf_model_predictions), \"\\n\")\n",
    "print(classification_report(labels_test, rf_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6f576a4-6e83-4165-b988-597bfdad91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = './models/rf_model.sav'\n",
    "pickle.dump(rf_model, open(filename, 'wb'))\n",
    "\n",
    "# # later, load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c36a5-1132-4f0a-b533-3e9fbcbd411a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fad2ff74-e307-4e2a-b7f7-784cecc6496a",
   "metadata": {},
   "source": [
    "## 5. Gradient Boosting: \n",
    "This is another ensemble learning algorithm that combines multiple weak learners to make a strong classifier. It's known for its high accuracy and ability to handle complex data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c9ff2-d4b7-43a4-9078-895f674bd93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# create GradientBoostingClassifier for multi-class classification\n",
    "gb_model = GradientBoostingClassifier(n_estimators=50, learning_rate=0.01, max_depth=3, random_state=1)\n",
    "\n",
    "# train the classifier on the training data\n",
    "gb_model.fit(features_train, labels_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "gb_model_predictions = gb_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29982dc6-95c1-447d-9e72-15b93430c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate the accuracy of the classifier\n",
    "print('\\nAccuracy: ', accuracy_score(labels_test, gb_model_predictions), \"\\n\")\n",
    "print(classification_report(labels_test, gb_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fded5d2-ec71-4e4b-b518-969e733538fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.4150604377654361 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.56      0.63       594\n",
      "           1       0.75      0.40      0.52       346\n",
      "           2       0.65      0.39      0.49       636\n",
      "           3       0.90      0.74      0.81       567\n",
      "           4       0.70      0.30      0.42       346\n",
      "           5       0.61      0.35      0.44       155\n",
      "           6       0.72      0.34      0.47       613\n",
      "           7       0.80      0.36      0.49       601\n",
      "           8       0.43      0.21      0.28       214\n",
      "           9       0.63      0.37      0.46       586\n",
      "          10       0.56      0.31      0.40       609\n",
      "          11       0.64      0.69      0.66       601\n",
      "          12       0.78      0.44      0.56       635\n",
      "          13       0.50      0.34      0.40       603\n",
      "          14       0.64      0.34      0.44       621\n",
      "          15       0.74      0.27      0.39       585\n",
      "          16       0.80      0.40      0.54       625\n",
      "          17       0.40      0.03      0.05       554\n",
      "          18       0.73      0.36      0.48       577\n",
      "          19       0.69      0.51      0.59       601\n",
      "          20       0.70      0.60      0.65       612\n",
      "          21       0.08      0.81      0.15       578\n",
      "          22       1.00      0.04      0.08       146\n",
      "          23       0.88      0.06      0.12       239\n",
      "\n",
      "    accuracy                           0.42     12244\n",
      "   macro avg       0.67      0.38      0.44     12244\n",
      "weighted avg       0.66      0.42      0.47     12244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate the accuracy of the classifier\n",
    "print('\\nAccuracy: ', accuracy_score(labels_test, gb_model_predictions), \"\\n\")\n",
    "print(classification_report(labels_test, gb_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc02373f-d482-4af8-8fb4-9d24b2491701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = './models/gb_model.sav'\n",
    "pickle.dump(gb_model, open(filename, 'wb'))\n",
    "\n",
    "# # later, load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385eaef-4fcb-473d-9f19-7ab28f229b53",
   "metadata": {},
   "source": [
    "## 6. Convolutional Neural Networks (CNN): \n",
    "This algorithm uses deep learning techniques to learn features from the input text data. It's effective for text classification tasks that involve identifying patterns in the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce025f00-f6d1-4439-af50-4224bf5d6f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# define the convolutional neural network\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=100, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=100, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=100, out_channels=100, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(100, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.permute(0, 2, 1)\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91593951-daa3-4e52-a769-a50f7f8092fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Exception ignored in: <function tqdm.__del__ at 0x000001E148F41AF0>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\tqdm\\std.py\", line 1162, in __del__\n",
      "    self.close()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\tqdm\\std.py\", line 1291, in close\n",
      "    if self.last_print_t < self.start_t + self.delay:\n",
      "AttributeError: 'tqdm' object has no attribute 'last_print_t'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [100, 2000, 3], expected input[1, 16, 2000] to have 2000 channels, but got 16 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11424\\2361407169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mcnn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11424\\2361407169.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cnn_model)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11424\\1361178184.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# x = x.permute(0, 2, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 309\u001b[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [100, 2000, 3], expected input[1, 16, 2000] to have 2000 channels, but got 16 channels instead"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# convert data to PyTorch tensors\n",
    "X_train = torch.tensor(features_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(labels_train, dtype=torch.long)\n",
    "X_test = torch.tensor(features_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(np.array(labels_test.values.tolist()), dtype=torch.long)\n",
    "\n",
    "# define hyperparameters and model architecture\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(categories)\n",
    "learning_rate = 3e-4\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "\n",
    "# create an instance of the TextCNN model\n",
    "cnn_model = TextCNN(input_dim, output_dim)\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# train the model\n",
    "def train(cnn_model):\n",
    "    for epoch in tqdm(range(num_epochs), total=len(range(num_epochs))):\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "        cnn_model.train()\n",
    "        for i in range(0, X_train.size(0), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            batch_x = X_train[i:i+batch_size]\n",
    "            batch_y = y_train[i:i+batch_size]\n",
    "            y_pred = cnn_model(batch_x)\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_acc += accuracy_score(batch_y.tolist(), torch.argmax(y_pred, dim=1).tolist())\n",
    "        train_loss /= (X_train.size(0) // batch_size)\n",
    "        train_acc /= (X_train.size(0) // batch_size)\n",
    "        print(f\"Train loss: {train_loss}, Train accuracy: {train_acc}\")\n",
    "        \n",
    "    return cnn_model\n",
    "\n",
    "# def evaluate():\n",
    "#     # evaluate the model on the test set\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         test_loss, test_acc = 0.0, 0.\n",
    "        \n",
    "\n",
    "\n",
    "cnn_model = train(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3a5805f-79ae-4379-b623-3bc5f4d6de6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24074    15\n",
       "5107      0\n",
       "12282    12\n",
       "119      17\n",
       "50268    10\n",
       "         ..\n",
       "5571     10\n",
       "15788    16\n",
       "1166     13\n",
       "37356     6\n",
       "39060     2\n",
       "Name: Category_target, Length: 12244, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c4123-9fe9-4e43-af43-26f477718e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
